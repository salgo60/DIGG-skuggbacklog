{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "102ece9c-7a33-4d57-b2b7-f6229269be29",
   "metadata": {},
   "source": [
    "## Uptime\n",
    "\n",
    "* [#85](https://github.com/salgo60/Svenskaforsamlingar/issues/85)\n",
    "* [RiksarkivetUptime.ipynb](https://github.com/salgo60/DIGG-skuggbacklog/blob/master/Notebook/RiksarkivetUptime.ipynb)\n",
    "   * körs under https://github.com/salgo60/DIGG-skuggbacklog/\n",
    "      * [Notebook/RiksarkivetUptime.ipynb](https://github.com/salgo60/DIGG-skuggbacklog/blob/master/Notebook/RiksarkivetUptime.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "893371ec-9d51-4728-8754-d3f907e35dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2026-01-06 13:26:53\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "timestamp = now.timestamp()\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Start:\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "547f67ab-b23d-4c61-ac87-691d96ee3158",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(git_commits_for_file(Path(\"history/riksarkivet-nad-se-ula-12231.yml\")))[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d957a7c3-7f97-4581-93fc-a08bebc657d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/salgo/Documents/GitHub/DIGG-skuggbacklog/docs')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DOCS_DIR = Path(\"../docs\").resolve()\n",
    "DOCS_DIR.mkdir(exist_ok=True)\n",
    "DOCS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b34bb7fc-a8cd-4494-aea1-33d8ee316348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "from dateutil import parser\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8155737e-a8b4-4480-b546-02d37b97ecba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "REPO_ROOT = Path(\"/Users/salgo/Documents/GitHub/DIGG-skuggbacklog\").resolve()\n",
    "assert (REPO_ROOT / \".git\").exists(), \"Not a git repository\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50a366bf-90b3-4f48-a678-d194923d42c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# KONFIGURATION\n",
    "# =========================\n",
    "\n",
    "HISTORY_DIR = Path(\"history\")\n",
    "\n",
    "FILES = {\n",
    "    \"riksarkivet_nad_se_ula_12231\": \"riksarkivet-nad-se-ula-12231.yml\",\n",
    "    \"riksarkivet_forskarsalen\": \"riksarkivet-forskarsalen.yml\",\n",
    "    \"riksarkivet_kyrkbok_c0005418\": \"riksarkivet-kyrkbok-c0005418.yml\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9782210e-08e8-4f4f-92ba-c502a31eda4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "from datetime import timezone\n",
    "\n",
    "def git_commits_for_file(path: Path):\n",
    "    rel_path = path.as_posix()  # t.ex. history/fil.yml\n",
    "\n",
    "    cmd = [\n",
    "        \"git\", \"log\",\n",
    "        \"--follow\",\n",
    "        \"--reverse\",\n",
    "        \"--format=%H|%cI\",\n",
    "        \"--\",                 # <-- ABSOLUT KRITISK\n",
    "        rel_path\n",
    "    ]\n",
    "\n",
    "    out = subprocess.check_output(\n",
    "        cmd,\n",
    "        cwd=REPO_ROOT,        # <-- ABSOLUT KRITISK\n",
    "        text=True\n",
    "    )\n",
    "\n",
    "    for line in out.strip().splitlines():\n",
    "        sha, ts = line.split(\"|\", 1)\n",
    "        yield sha, parser.isoparse(ts).astimezone(timezone.utc)\n",
    "\n",
    "import yaml\n",
    "\n",
    "def load_file_at_commit(commit: str, path: Path) -> dict:\n",
    "    rel_path = path.as_posix()\n",
    "\n",
    "    cmd = [\n",
    "        \"git\", \"show\",\n",
    "        f\"{commit}:{rel_path}\"\n",
    "    ]\n",
    "\n",
    "    content = subprocess.check_output(\n",
    "        cmd,\n",
    "        cwd=REPO_ROOT,\n",
    "        text=True\n",
    "    )\n",
    "\n",
    "    return yaml.safe_load(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bda7ea0b-e4c6-423e-a602-47f82d330c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_status_timeseries(endpoint: str, filename: str) -> pd.DataFrame:\n",
    "    path = HISTORY_DIR / filename\n",
    "    rows = []\n",
    "\n",
    "    for commit, ts in git_commits_for_file(path):\n",
    "        data = load_file_at_commit(commit, path)\n",
    "        rows.append({\n",
    "            \"endpoint\": endpoint,\n",
    "            \"commit\": commit,\n",
    "            \"time\": ts,\n",
    "            \"status\": data.get(\"status\"),\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb7524f9-1aa0-44fe-958d-33e0b852db17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_incidents(ts_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    incidents = []\n",
    "\n",
    "    ts_df = ts_df.sort_values(\"time\").reset_index(drop=True)\n",
    "\n",
    "    current_start = None\n",
    "\n",
    "    for i, row in ts_df.iterrows():\n",
    "        status = row[\"status\"]\n",
    "        time = row[\"time\"]\n",
    "\n",
    "        if status == \"down\" and current_start is None:\n",
    "            # up → down\n",
    "            current_start = time\n",
    "\n",
    "        elif status == \"up\" and current_start is not None:\n",
    "            # down → up\n",
    "            duration = (time - current_start).total_seconds() / 60\n",
    "            incidents.append({\n",
    "                \"endpoint\": row[\"endpoint\"],\n",
    "                \"start\": current_start,\n",
    "                \"end\": time,\n",
    "                \"duration_min\": round(duration, 2),\n",
    "                \"ongoing\": False,\n",
    "            })\n",
    "            current_start = None\n",
    "\n",
    "    # Om den slutar i down → pågående incident\n",
    "    if current_start is not None:\n",
    "        end = datetime.now(timezone.utc)\n",
    "        duration = (end - current_start).total_seconds() / 60\n",
    "        incidents.append({\n",
    "            \"endpoint\": ts_df.iloc[-1][\"endpoint\"],\n",
    "            \"start\": current_start,\n",
    "            \"end\": end,\n",
    "            \"duration_min\": round(duration, 2),\n",
    "            \"ongoing\": True,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(incidents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173bf5e0-6877-4e2e-9cec-130f03786a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_incidents = []\n",
    "\n",
    "for endpoint, filename in FILES.items():\n",
    "    ts_df = extract_status_timeseries(endpoint, filename)\n",
    "    incidents = build_incidents(ts_df)\n",
    "    all_incidents.append(incidents)\n",
    "\n",
    "incidents_df = pd.concat(all_incidents, ignore_index=True)\n",
    "incidents_df.sort_values(\"start\", inplace=True)\n",
    "\n",
    "incidents_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0106308-aabc-4570-9584-a4a42e4c98a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_df[\"downtime_days\"] = (\n",
    "    incidents_df[\"duration_min\"] / 60 / 24\n",
    ").round(2)\n",
    "\n",
    "incidents_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c567b8b3-2181-411b-99dd-fe8d929b4f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df = pd.read_csv(\"test.csv\")\n",
    "#df = incidents_df.drop(columns=[\"Unnamed: 0\"])\n",
    "incidents_df.to_csv(\"incidents_clean.csv\", index=False)\n",
    "incidents_df.to_csv(\n",
    "    DOCS_DIR / \"incidents_clean_2.csv\",\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb8fdbb-8d7c-4f69-a384-a5c19264e689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1f8771-6b68-461e-9e55-847d44857871",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = (\n",
    "    df.groupby(\"endpoint\")\n",
    "      .agg(\n",
    "          incidents=(\"duration_min\", \"count\"),\n",
    "          total_downtime_min=(\"duration_min\", \"sum\"),\n",
    "          max_incident_min=(\"duration_min\", \"max\"),\n",
    "          median_incident_min=(\"duration_min\", \"median\"),\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "summary[\"total_downtime_hours\"] = (summary[\"total_downtime_min\"] / 60).round(2)\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9972cf-4588-4e57-94dd-d0a40e2b3bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"incidents_clean.csv\", parse_dates=[\"start\", \"end\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1e23b5-dd30-43e5-8d5b-0d8abf85210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "rows = []\n",
    "\n",
    "for _, r in df.iterrows():\n",
    "    day = r[\"start\"].date()\n",
    "    end_day = r[\"end\"].date()\n",
    "\n",
    "    while day <= end_day:\n",
    "        rows.append({\n",
    "            \"endpoint\": r[\"endpoint\"],\n",
    "            \"date\": day,\n",
    "            \"duration_min\": r[\"duration_min\"],\n",
    "        })\n",
    "        day += timedelta(days=1)\n",
    "\n",
    "calendar_df = pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de21f656-a83c-4d61-a422-a4a095c7dc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_daily = (\n",
    "    calendar_df\n",
    "    .groupby([\"endpoint\", \"date\"])\n",
    "    .agg(\n",
    "        incidents=(\"duration_min\", \"count\"),\n",
    "        downtime_min=(\"duration_min\", \"sum\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "calendar_daily.to_csv(\"calendar_daily_2.csv\", index=False)\n",
    "calendar_daily.to_csv(\n",
    "    DOCS_DIR / \"calendar_daily_2.csv\",\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96986a08-f670-48a9-99a0-f1d0c5c9ed76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import subprocess\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "commit = subprocess.check_output(\n",
    "    [\"git\", \"rev-parse\", \"--short\", \"HEAD\"],\n",
    "    text=True\n",
    ").strip()\n",
    "\n",
    "meta = {\n",
    "    \"generated_at\": datetime.now(timezone.utc).isoformat(timespec=\"seconds\"),\n",
    "    \"commit\": commit,\n",
    "}\n",
    "\n",
    "with open(DOCS_DIR / \"meta_2.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(meta, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e93ced2-a2f3-4dc9-af6a-7704d4823404",
   "metadata": {},
   "outputs": [],
   "source": [
    " # End timer and calculate duration\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time# Bygg audit-lager för den här etappen\n",
    "\n",
    "# Print current date and total time\n",
    "print(\"Date:\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "minutes, seconds = divmod(elapsed_time, 60)\n",
    "print(\"Total time elapsed: {:02.0f} minutes {:05.2f} seconds\".format(minutes, seconds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0edca4-b7d6-4f90-b61d-94c9fba2b1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d3772e-d656-4905-80f2-cd017b20b847",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
